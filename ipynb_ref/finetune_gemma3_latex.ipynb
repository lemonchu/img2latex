{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB48i6c3Ikkn",
        "outputId": "ea7fece5-afa8-4116-88e9-ee6ccede8af0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch>=2.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.6.0)\n",
            "Requirement already satisfied: tensorboard in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.15.1)\n",
            "Requirement already satisfied: torchvision in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.21.0)\n",
            "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.4.0) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard) (2.1.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard) (1.71.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard) (1.26.4)\n",
            "Collecting protobuf<4.24,>=3.19.6 (from tensorboard)\n",
            "  Using cached protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard) (75.8.0)\n",
            "Requirement already satisfied: six>1.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
            "Using cached protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "Successfully installed protobuf-4.23.4\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: transformers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.51.0)\n",
            "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers) (2025.1.31)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: datasets==3.3.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (3.3.2)\n",
            "Requirement already satisfied: accelerate==1.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.4.0)\n",
            "Requirement already satisfied: evaluate==0.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.4.3)\n",
            "Requirement already satisfied: bitsandbytes==0.45.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.45.3)\n",
            "Requirement already satisfied: trl==0.15.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.15.2)\n",
            "Requirement already satisfied: peft==0.14.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.14.0)\n",
            "Requirement already satisfied: pillow==11.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (11.1.0)\n",
            "Requirement already satisfied: protobuf in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.23.4)\n",
            "Collecting protobuf\n",
            "  Using cached protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: sentencepiece in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.2.0)\n",
            "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==3.3.2) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==3.3.2) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==3.3.2) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==3.3.2) (0.3.8)\n",
            "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==3.3.2) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==3.3.2) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==3.3.2) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==3.3.2) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==3.3.2) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets==3.3.2) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==3.3.2) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==3.3.2) (0.30.1)\n",
            "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==3.3.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets==3.3.2) (6.0.2)\n",
            "Requirement already satisfied: psutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate==1.4.0) (7.0.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate==1.4.0) (2.6.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from accelerate==1.4.0) (0.5.3)\n",
            "Requirement already satisfied: rich in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from trl==0.15.2) (13.9.4)\n",
            "Requirement already satisfied: transformers>=4.46.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from trl==0.15.2) (4.51.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==3.3.2) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==3.3.2) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==3.3.2) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==3.3.2) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==3.3.2) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==3.3.2) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==3.3.2) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->datasets==3.3.2) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets==3.3.2) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.2->datasets==3.3.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.2->datasets==3.3.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.2->datasets==3.3.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.32.2->datasets==3.3.2) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.4.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate==1.4.0) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers>=4.46.0->trl==0.15.2) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers>=4.46.0->trl==0.15.2) (0.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets==3.3.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets==3.3.2) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets==3.3.2) (2025.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->trl==0.15.2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->trl==0.15.2) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl==0.15.2) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.3.2) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate==1.4.0) (3.0.2)\n",
            "Using cached protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.23.4\n",
            "    Uninstalling protobuf-4.23.4:\n",
            "      Successfully uninstalled protobuf-4.23.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 6.30.2 which is incompatible.\n",
            "wandb 0.19.7 requires protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0; python_version > \"3.9\" and sys_platform == \"linux\", but you have protobuf 6.30.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-6.30.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: wandb==0.19.7 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.19.7)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb==0.19.7) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb==0.19.7) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb==0.19.7) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb==0.19.7) (4.3.7)\n",
            "Collecting protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 (from wandb==0.19.7)\n",
            "  Using cached protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb==0.19.7) (7.0.0)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb==0.19.7) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb==0.19.7) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb==0.19.7) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb==0.19.7) (2.25.1)\n",
            "Requirement already satisfied: setproctitle in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb==0.19.7) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb==0.19.7) (75.8.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb==0.19.7) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb==0.19.7) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb==0.19.7) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic<3,>=2.6->wandb==0.19.7) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic<3,>=2.6->wandb==0.19.7) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb==0.19.7) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb==0.19.7) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb==0.19.7) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb==0.19.7) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb==0.19.7) (5.0.2)\n",
            "Using cached protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 6.30.2\n",
            "    Uninstalling protobuf-6.30.2:\n",
            "      Successfully uninstalled protobuf-6.30.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 5.29.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-5.29.4\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install Pytorch & other libraries\n",
        "%pip install \"torch>=2.4.0\" tensorboard torchvision\n",
        "%pip install -U transformers\n",
        "\n",
        "# Install Hugging Face libraries\n",
        "%pip install  --upgrade \\\n",
        "  \"datasets==3.3.2\" \\\n",
        "  \"accelerate==1.4.0\" \\\n",
        "  \"evaluate==0.4.3\" \\\n",
        "  \"bitsandbytes==0.45.3\" \\\n",
        "  \"trl==0.15.2\" \\\n",
        "  \"peft==0.14.0\" \\\n",
        "  \"pillow==11.1.0\" \\\n",
        "  protobuf \\\n",
        "  sentencepiece\n",
        "\n",
        "%pip install wandb==0.19.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "7fec9eb62c234dd28b90c5d95a1a1516",
            "ce52c05a92354e1790580c0a1cc99b91",
            "9a060499ac9540078832cecbd0734cd6",
            "7f5999974f91454592055cefa9999017",
            "fddee47e4bc7423da72ccc61522bed6d",
            "d9e9dac7c1124fe888d9d535ecfba522",
            "9bb25ff24ab049ec9effde278b4dbb7c",
            "c9354b185e124903acd0fe8deee1518f",
            "81d9ea6500d84953a7dd9d05bdc095ca",
            "b17487c219374f97a61ba41b87f27a88",
            "5896c2b61a1c4691bd3cde8e88fab612",
            "141f930c03804c0199b77bad9f4a4e3b",
            "65b049c349b744f9b4135e100a5179e1",
            "81e55631302a487ba3375dc3c848c3e6",
            "a2fa6a6086664fcab68bd59f725c2be6",
            "7d997f7d997b463cb08872d29e74c7b3",
            "32b3046c42244f63aea88d917176b8e4",
            "5958a748d483474f81a9b6627d5fdd3a",
            "1d1f0632ebbd406e9173298c5821a832",
            "ce7e50a60fa5448eb10518228133c7b6"
          ]
        },
        "id": "5fxjxzgXIxay",
        "outputId": "a2379430-1fb2-40ad-8463-0c14bb507d21"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8052c01cf4384b9884cbfcec066d4fa7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token has not been saved to git credential helper.\n"
          ]
        }
      ],
      "source": [
        "import huggingface_hub\n",
        "huggingface_hub.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV3fCqUvI4Ex",
        "outputId": "015eb250-d5af-4eea-98b6-9cdf27819790"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from PIL import Image\n",
        "\n",
        "instruction = 'Convert the equation images to LaTeX equations.'\n",
        "def convert_to_conversation(sample):\n",
        "    conversation = [\n",
        "        { 'role': 'user',\n",
        "          'content' : [\n",
        "            {'type' : 'text',  'text'  : instruction},\n",
        "            {'type' : 'image', 'image' : sample['image']} ]\n",
        "        },\n",
        "        { 'role' : 'assistant',\n",
        "          'content' : [\n",
        "            {'type' : 'text',  'text'  : sample['text']} ]\n",
        "        },\n",
        "    ]\n",
        "    return { 'messages' : conversation }\n",
        "\n",
        "\n",
        "def process_vision_info(messages: list[dict]) -> list[Image.Image]:\n",
        "    image_inputs = []\n",
        "    # Iterate through each conversation\n",
        "    for msg in messages:\n",
        "        # Get content (ensure it's a list)\n",
        "        content = msg.get(\"content\", [])\n",
        "        if not isinstance(content, list):\n",
        "            content = [content]\n",
        "\n",
        "        # Check each content element for images\n",
        "        for element in content:\n",
        "            if isinstance(element, dict) and (\n",
        "                \"image\" in element or element.get(\"type\") == \"image\"\n",
        "            ):\n",
        "                # Get the image and convert to RGB\n",
        "                if \"image\" in element:\n",
        "                    image = element[\"image\"]\n",
        "                else:\n",
        "                    image = element\n",
        "                image_inputs.append(image.convert(\"RGB\"))\n",
        "    return image_inputs\n",
        "\n",
        "# Load dataset from the hub\n",
        "#dataset = load_dataset(\"unsloth/LaTeX_OCR\", split=\"train\")\n",
        "dataset_train = load_dataset('unsloth/LaTeX_OCR', split='train[:3000]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RKfvJjbEJXab",
        "outputId": "f3ec1517-5f00-487a-ffec-c3bcc8f6cffc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x78f7171ea2c0>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "train_image = dataset_train[0]['image']\n",
        "plt.imshow(train_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYoKYmTaJY8Z",
        "outputId": "88f1ea3d-5335-47c6-fa9b-54cc8481fd7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{ \\frac { N } { M } } \\in { \\bf Z } , { \\frac { M } { P } } \\in { \\bf Z } , { \\frac { P } { Q } } \\in { \\bf Z }\n"
          ]
        }
      ],
      "source": [
        "print(dataset_train[0]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ4naGRML22X",
        "outputId": "a43fda82-76d6-49c5-f92e-297368d1f936"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3000/3000 [00:01<00:00, 2425.53it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "converted_dataset_train = [\n",
        "    convert_to_conversation(sample) \\\n",
        "    for sample in tqdm(dataset_train, total=len(dataset_train))\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1_ALwg6L-rr",
        "outputId": "99a66343-46e6-4cad-826b-ac7a0d3d421a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': 'Convert the equation images to LaTeX equations.'}, {'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=160x40 at 0x78F7172CB6A0>}]}, {'role': 'assistant', 'content': [{'type': 'text', 'text': '{ \\\\frac { N } { M } } \\\\in { \\\\bf Z } , { \\\\frac { M } { P } } \\\\in { \\\\bf Z } , { \\\\frac { P } { Q } } \\\\in { \\\\bf Z }'}]}]}\n"
          ]
        }
      ],
      "source": [
        "print(converted_dataset_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flash-attn in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.7.4.post1)\n",
            "Requirement already satisfied: torch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flash-attn) (2.6.0)\n",
            "Requirement already satisfied: einops in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from flash-attn) (0.8.1)\n",
            "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->flash-attn) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->flash-attn) (4.12.2)\n",
            "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->flash-attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->flash-attn) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->flash-attn) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->flash-attn) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->flash-attn) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->flash-attn) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->flash-attn) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->flash-attn) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->flash-attn) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->flash-attn) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->flash-attn) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->flash-attn) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch->flash-attn) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install flash-attn --no-build-isolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "dadecfc5e56c4f57b07dfd38930a03f3",
            "5f455c39f2f648c196cdb76154ca3f72",
            "5477ef249f0f4d6c8e86eb6e7a248438",
            "64aaa0d8ae374a45ab14a4c1150a2209",
            "d4d13c4e9cc7444aa011ac045c638db8",
            "ea141cbca2ed4389beecf8d9b018a261",
            "5d0e25cd97dc4820814d8995533fe513",
            "89ad607ed583402d94fba906081b22cc",
            "40321bada8b14da28729bea9998a72fd",
            "9677ca77a4df4dd4afbd4e11823d500d",
            "a3dab7b5de3142ada052c0524502159b"
          ]
        },
        "id": "CPbhmlTBLS3S",
        "outputId": "85377313-c794-42b9-ae1a-aa956ef60751"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a45d86b003e436487e845475c894a1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoProcessor, AutoModelForImageTextToText, BitsAndBytesConfig\n",
        "\n",
        "# Hugging Face model id\n",
        "model_id = \"google/gemma-3-4b-pt\" # or `google/gemma-3-12b-pt`, `google/gemma-3-27-pt`\n",
        "\n",
        "# Define model init arguments\n",
        "model_kwargs = dict(\n",
        "    attn_implementation=\"flash_attention_2\", \n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\", # Let torch decide how to load the model\n",
        ")\n",
        "\n",
        "# BitsAndBytesConfig int-4 config\n",
        "model_kwargs[\"quantization_config\"] = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=model_kwargs[\"torch_dtype\"],\n",
        "    bnb_4bit_quant_storage=model_kwargs[\"torch_dtype\"],\n",
        ")\n",
        "\n",
        "# Load model and tokenizer\n",
        "model = AutoModelForImageTextToText.from_pretrained(model_id, **model_kwargs)\n",
        "processor = AutoProcessor.from_pretrained(\"google/gemma-3-4b-it\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7IXph_z_LXi5"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,\n",
        "    r=8,\n",
        "    bias=\"none\",\n",
        "    target_modules=[\n",
        " 'down_proj',\n",
        " 'o_proj',\n",
        " 'k_proj',\n",
        " 'q_proj',\n",
        " 'gate_proj',\n",
        " 'up_proj',\n",
        " 'v_proj'],\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    modules_to_save=[\n",
        "        \"lm_head\",\n",
        "        \"embed_tokens\",\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fWV1FUBjLZi0"
      },
      "outputs": [],
      "source": [
        "from trl import SFTConfig\n",
        "\n",
        "args=SFTConfig(\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=10,\n",
        "        num_train_epochs=1, # For full training runs over the dataset.\n",
        "        learning_rate=2e-4,\n",
        "        bf16=True,\n",
        "        logging_steps=200,\n",
        "        save_strategy='steps',\n",
        "        save_steps=200,\n",
        "        save_total_limit=2,\n",
        "        optim='adamw_8bit',\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type='linear',\n",
        "        seed=3407,\n",
        "        output_dir='outputs',\n",
        "        report_to='none',     \n",
        "        remove_unused_columns=False,\n",
        "        dataset_text_field='',\n",
        "        dataset_kwargs={'skip_prepare_dataset': True},\n",
        "        max_seq_length=1024,\n",
        ")\n",
        "\n",
        "# Create a data collator to encode text and image pairs\n",
        "def collate_fn(examples):\n",
        "    texts = []\n",
        "    images = []\n",
        "    for example in examples:\n",
        "        image_inputs = process_vision_info(example[\"messages\"])\n",
        "        text = processor.apply_chat_template(\n",
        "            example[\"messages\"], add_generation_prompt=False, tokenize=False\n",
        "        )\n",
        "        texts.append(text.strip())\n",
        "        images.append(image_inputs)\n",
        "\n",
        "    # Tokenize the texts and process the images\n",
        "    batch = processor(text=texts, images=images, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "    # The labels are the input_ids, and we mask the padding tokens and image tokens in the loss computation\n",
        "    labels = batch[\"input_ids\"].clone()\n",
        "\n",
        "    # Mask image tokens\n",
        "    image_token_id = [\n",
        "        processor.tokenizer.convert_tokens_to_ids(\n",
        "            processor.tokenizer.special_tokens_map[\"boi_token\"]\n",
        "        )\n",
        "    ]\n",
        "    # Mask tokens for not being used in the loss computation\n",
        "    labels[labels == processor.tokenizer.pad_token_id] = -100\n",
        "    labels[labels == image_token_id] = -100\n",
        "    labels[labels == 262144] = -100\n",
        "\n",
        "    batch[\"labels\"] = labels\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flDEy_qALcSm",
        "outputId": "16b592ca-779d-47da-b694-a10371e8a473"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=converted_dataset_train,\n",
        "    peft_config=peft_config,\n",
        "    processing_class=processor,\n",
        "    data_collator=collate_fn,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "VjM-TpaILeH8",
        "outputId": "ecf8104a-6a6e-4fef-883b-755a1fbb804a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\n",
            "It is strongly recommended to train Gemma3 models with the `eager` attention implementation instead of `flash_attention_2`. Use `eager` with `AutoModelForCausalLM.from_pretrained('<path-to-checkpoint>', attn_implementation='eager')`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [750/750 1:02:39, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.379300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.465800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.383500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Start training, the model will be automatically saved to the Hub and the output directory\n",
        "trainer.train()\n",
        "\n",
        "# Save the final model again to the Hugging Face Hub\n",
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "M6lQXIoUux5O"
      },
      "outputs": [],
      "source": [
        "# free the memory again\n",
        "del model\n",
        "del trainer\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8160278aeda4358a88b83182b410ce1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Load Model with PEFT adapter\n",
        "model = AutoModelForImageTextToText.from_pretrained(\n",
        "  args.output_dir,\n",
        "  device_map=\"auto\",\n",
        "  torch_dtype=torch.bfloat16,\n",
        "  attn_implementation=\"flash_attention_2\",\n",
        ")\n",
        "processor = AutoProcessor.from_pretrained(args.output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "H ^ { \\prime } = \\beta N \\int d \\lambda \\biggl \\{ \\frac { 1 } { 2 \\beta ^ { 2 } N ^ { 2 } } \\partial _ { \\lambda } \\zeta ^ { \\dagger } \\partial _ { \\lambda } \\zeta + V ( \\lambda ) \\zeta ^ { \\dagger } \\zeta \\biggr \\} .\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "image = Image.open(\"/teamspace/studios/this_studio/latex1.jpg\").convert(\"RGB\")\n",
        "instruction = 'Convert the equation images to LaTeX equations.'\n",
        "\n",
        "\n",
        "def generate_equation(model, processor):\n",
        "    # Convert sample into messages and then apply the chat template\n",
        "    messages = [\n",
        "        { 'role': 'user',\n",
        "          'content' : [\n",
        "            {'type' : 'text',  'text'  : instruction},\n",
        "            {'type' : 'image', 'image' : image} ]\n",
        "        },\n",
        "    ]\n",
        "    text = processor.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "    # Process the image and text\n",
        "    image_inputs = process_vision_info(messages)\n",
        "    # Tokenize the text and process the images\n",
        "    inputs = processor(\n",
        "        text=[text],\n",
        "        images=image_inputs,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    # Move the inputs to the device\n",
        "    inputs = inputs.to(model.device)\n",
        "    \n",
        "    # Generate the output\n",
        "    stop_token_ids = [processor.tokenizer.eos_token_id, processor.tokenizer.convert_tokens_to_ids(\"<end_of_turn>\")]\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=256, top_p=1.0, do_sample=True, temperature=0.8, eos_token_id=stop_token_ids, disable_compile=True)\n",
        "    # Trim the generation and decode the output to text\n",
        "    generated_ids_trimmed = [out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)]\n",
        "    output_text = processor.batch_decode(\n",
        "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        "    )\n",
        "    return output_text[0]\n",
        "\n",
        "# generate the description\n",
        "description = generate_equation(model, processor)\n",
        "print(description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E _ { 1 } ^ { - } ( j _ { 2 } ) = ( - 1 ) ^ { n } \\prod _ { k = 1 } ^ { n } c _ { k } \\mathcal { E } ^ { n } ( \\bar { y } _ { 1 } , \\dots , \\bar { y } _ { n } ) + \\mathrm { o t h e r t e r m s } .\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "image = Image.open(\"/teamspace/studios/this_studio/latex6.jpg\").convert(\"RGB\")\n",
        "instruction = 'Convert the equation images to LaTeX equations.'\n",
        "\n",
        "\n",
        "def generate_equation(model, processor):\n",
        "    # Convert sample into messages and then apply the chat template\n",
        "    messages = [\n",
        "        { 'role': 'user',\n",
        "          'content' : [\n",
        "            {'type' : 'text',  'text'  : instruction},\n",
        "            {'type' : 'image', 'image' : image} ]\n",
        "        },\n",
        "    ]\n",
        "    text = processor.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "    # Process the image and text\n",
        "    image_inputs = process_vision_info(messages)\n",
        "    # Tokenize the text and process the images\n",
        "    inputs = processor(\n",
        "        text=[text],\n",
        "        images=image_inputs,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    # Move the inputs to the device\n",
        "    inputs = inputs.to(model.device)\n",
        "    \n",
        "    # Generate the output\n",
        "    stop_token_ids = [processor.tokenizer.eos_token_id, processor.tokenizer.convert_tokens_to_ids(\"<end_of_turn>\")]\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=256, top_p=1.0, do_sample=True, temperature=0.8, eos_token_id=stop_token_ids, disable_compile=True)\n",
        "    # Trim the generation and decode the output to text\n",
        "    generated_ids_trimmed = [out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)]\n",
        "    output_text = processor.batch_decode(\n",
        "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        "    )\n",
        "    return output_text[0]\n",
        "\n",
        "# generate the description\n",
        "description = generate_equation(model, processor)\n",
        "print(description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\left[ \\left[ B _ { n } ^ { + } , b _ { 2 } ^ { - } \\right] , b _ { 2 } ^ { + } \\right] = n B _ { n } ^ { + } , \\quad \\left[ \\left[ B _ { n } ^ { - } , b _ { 2 } ^ { + } \\right] , b _ { 2 } ^ { - } \\right] = n B _ { n } ^ { - } .\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "image = Image.open(\"/teamspace/studios/this_studio/latex2.jpg\").convert(\"RGB\")\n",
        "instruction = 'Convert the equation images to LaTeX equations.'\n",
        "\n",
        "\n",
        "def generate_equation(model, processor):\n",
        "    # Convert sample into messages and then apply the chat template\n",
        "    messages = [\n",
        "        { 'role': 'user',\n",
        "          'content' : [\n",
        "            {'type' : 'text',  'text'  : instruction},\n",
        "            {'type' : 'image', 'image' : image} ]\n",
        "        },\n",
        "    ]\n",
        "    text = processor.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "    # Process the image and text\n",
        "    image_inputs = process_vision_info(messages)\n",
        "    # Tokenize the text and process the images\n",
        "    inputs = processor(\n",
        "        text=[text],\n",
        "        images=image_inputs,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    # Move the inputs to the device\n",
        "    inputs = inputs.to(model.device)\n",
        "    \n",
        "    # Generate the output\n",
        "    stop_token_ids = [processor.tokenizer.eos_token_id, processor.tokenizer.convert_tokens_to_ids(\"<end_of_turn>\")]\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=256, top_p=1.0, do_sample=True, temperature=0.8, eos_token_id=stop_token_ids, disable_compile=True)\n",
        "    # Trim the generation and decode the output to text\n",
        "    generated_ids_trimmed = [out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)]\n",
        "    output_text = processor.batch_decode(\n",
        "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        "    )\n",
        "    return output_text[0]\n",
        "\n",
        "# generate the description\n",
        "description = generate_equation(model, processor)\n",
        "print(description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+ \\int d ^ { 3 } x J _ { \\mu } ^ { \\prime } ( x ) a _ { \\mu } ( x ) + \\int d ^ { 3 } x J _ { s } ^ { \\prime } ( x ) \\displaystyle \\varphi ( x ) ,\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "image = Image.open(\"/teamspace/studios/this_studio/latex3.jpg\").convert(\"RGB\")\n",
        "instruction = 'Convert the equation images to LaTeX equations.'\n",
        "\n",
        "\n",
        "def generate_equation(model, processor):\n",
        "    # Convert sample into messages and then apply the chat template\n",
        "    messages = [\n",
        "        { 'role': 'user',\n",
        "          'content' : [\n",
        "            {'type' : 'text',  'text'  : instruction},\n",
        "            {'type' : 'image', 'image' : image} ]\n",
        "        },\n",
        "    ]\n",
        "    text = processor.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "    # Process the image and text\n",
        "    image_inputs = process_vision_info(messages)\n",
        "    # Tokenize the text and process the images\n",
        "    inputs = processor(\n",
        "        text=[text],\n",
        "        images=image_inputs,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    # Move the inputs to the device\n",
        "    inputs = inputs.to(model.device)\n",
        "    \n",
        "    # Generate the output\n",
        "    stop_token_ids = [processor.tokenizer.eos_token_id, processor.tokenizer.convert_tokens_to_ids(\"<end_of_turn>\")]\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=256, top_p=1.0, do_sample=True, temperature=0.8, eos_token_id=stop_token_ids, disable_compile=True)\n",
        "    # Trim the generation and decode the output to text\n",
        "    generated_ids_trimmed = [out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)]\n",
        "    output_text = processor.batch_decode(\n",
        "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        "    )\n",
        "    return output_text[0]\n",
        "\n",
        "# generate the description\n",
        "description = generate_equation(model, processor)\n",
        "print(description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "M = \\frac { V _ { p } \\Omega _ { d - 1 } } { 1 6 \\pi G } \\rho _ { 0 } ^ { d - 2 } \\big [ d - 1 + ( d - 2 ) \\sinh ^ { 2 } \\alpha \\big ] \\ .\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "image = Image.open(\"/teamspace/studios/this_studio/latex4.jpg\").convert(\"RGB\")\n",
        "instruction = 'Convert the equation images to LaTeX equations.'\n",
        "\n",
        "\n",
        "def generate_equation(model, processor):\n",
        "    # Convert sample into messages and then apply the chat template\n",
        "    messages = [\n",
        "        { 'role': 'user',\n",
        "          'content' : [\n",
        "            {'type' : 'text',  'text'  : instruction},\n",
        "            {'type' : 'image', 'image' : image} ]\n",
        "        },\n",
        "    ]\n",
        "    text = processor.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "    # Process the image and text\n",
        "    image_inputs = process_vision_info(messages)\n",
        "    # Tokenize the text and process the images\n",
        "    inputs = processor(\n",
        "        text=[text],\n",
        "        images=image_inputs,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    # Move the inputs to the device\n",
        "    inputs = inputs.to(model.device)\n",
        "    \n",
        "    # Generate the output\n",
        "    stop_token_ids = [processor.tokenizer.eos_token_id, processor.tokenizer.convert_tokens_to_ids(\"<end_of_turn>\")]\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=256, top_p=1.0, do_sample=True, temperature=0.8, eos_token_id=stop_token_ids, disable_compile=True)\n",
        "    # Trim the generation and decode the output to text\n",
        "    generated_ids_trimmed = [out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)]\n",
        "    output_text = processor.batch_decode(\n",
        "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        "    )\n",
        "    return output_text[0]\n",
        "\n",
        "# generate the description\n",
        "description = generate_equation(model, processor)\n",
        "print(description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\lambda _ { R } \\equiv { \\frac { 1 } { 3 ! } } \\left| \\frac { d ^ { 4 } \\varphi ( \\Phi ) } { d \\Phi ^ { 4 } } \\right| _ { \\Phi = 0 } = \\lambda { \\frac { 1 - 6 \\lambda I _ { ( 2 ) } [ m _ { R } ^ { 2 } ] } { 1 + 3 \\lambda I _ { ( 2 ) } [ m _ { R } ^ { 2 } ] } } ,\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "image = Image.open(\"/teamspace/studios/this_studio/latex5.jpg\").convert(\"RGB\")\n",
        "instruction = 'Convert the equation images to LaTeX equations.'\n",
        "\n",
        "\n",
        "def generate_equation(model, processor):\n",
        "    # Convert sample into messages and then apply the chat template\n",
        "    messages = [\n",
        "        { 'role': 'user',\n",
        "          'content' : [\n",
        "            {'type' : 'text',  'text'  : instruction},\n",
        "            {'type' : 'image', 'image' : image} ]\n",
        "        },\n",
        "    ]\n",
        "    text = processor.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "    # Process the image and text\n",
        "    image_inputs = process_vision_info(messages)\n",
        "    # Tokenize the text and process the images\n",
        "    inputs = processor(\n",
        "        text=[text],\n",
        "        images=image_inputs,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    # Move the inputs to the device\n",
        "    inputs = inputs.to(model.device)\n",
        "    \n",
        "    # Generate the output\n",
        "    stop_token_ids = [processor.tokenizer.eos_token_id, processor.tokenizer.convert_tokens_to_ids(\"<end_of_turn>\")]\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=256, top_p=1.0, do_sample=True, temperature=0.8, eos_token_id=stop_token_ids, disable_compile=True)\n",
        "    # Trim the generation and decode the output to text\n",
        "    generated_ids_trimmed = [out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)]\n",
        "    output_text = processor.batch_decode(\n",
        "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        "    )\n",
        "    return output_text[0]\n",
        "\n",
        "# generate the description\n",
        "description = generate_equation(model, processor)\n",
        "print(description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\frac { 1 } { ( \\pi ) ^ { 4 } } \\int \\int d ^ { 4 } \\vec { x } \\phi ^ { n } ( \\vec { x } ) \\neq \\frac { 1 } { ( \\pi ) ^ { 4 } } \\int d ^ { 4 } x \\phi ^ { n } ( x ) \\qquad n \\geq 2\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "image = Image.open(\"/teamspace/studios/this_studio/latex7_test.jpg\").convert(\"RGB\")\n",
        "instruction = 'Convert the equation images to LaTeX equations.'\n",
        "\n",
        "\n",
        "def generate_equation(model, processor):\n",
        "    # Convert sample into messages and then apply the chat template\n",
        "    messages = [\n",
        "        { 'role': 'user',\n",
        "          'content' : [\n",
        "            {'type' : 'text',  'text'  : instruction},\n",
        "            {'type' : 'image', 'image' : image} ]\n",
        "        },\n",
        "    ]\n",
        "    text = processor.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "    # Process the image and text\n",
        "    image_inputs = process_vision_info(messages)\n",
        "    # Tokenize the text and process the images\n",
        "    inputs = processor(\n",
        "        text=[text],\n",
        "        images=image_inputs,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    # Move the inputs to the device\n",
        "    inputs = inputs.to(model.device)\n",
        "    \n",
        "    # Generate the output\n",
        "    stop_token_ids = [processor.tokenizer.eos_token_id, processor.tokenizer.convert_tokens_to_ids(\"<end_of_turn>\")]\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=256, top_p=1.0, do_sample=True, temperature=0.8, eos_token_id=stop_token_ids, disable_compile=True)\n",
        "    # Trim the generation and decode the output to text\n",
        "    generated_ids_trimmed = [out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)]\n",
        "    output_text = processor.batch_decode(\n",
        "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        "    )\n",
        "    return output_text[0]\n",
        "\n",
        "# generate the description\n",
        "description = generate_equation(model, processor)\n",
        "print(description)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "141f930c03804c0199b77bad9f4a4e3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d1f0632ebbd406e9173298c5821a832": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32b3046c42244f63aea88d917176b8e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40321bada8b14da28729bea9998a72fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5477ef249f0f4d6c8e86eb6e7a248438": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89ad607ed583402d94fba906081b22cc",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40321bada8b14da28729bea9998a72fd",
            "value": 2
          }
        },
        "5896c2b61a1c4691bd3cde8e88fab612": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5958a748d483474f81a9b6627d5fdd3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d1f0632ebbd406e9173298c5821a832",
            "placeholder": "​",
            "style": "IPY_MODEL_ce7e50a60fa5448eb10518228133c7b6",
            "value": "Connecting..."
          }
        },
        "5d0e25cd97dc4820814d8995533fe513": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f455c39f2f648c196cdb76154ca3f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea141cbca2ed4389beecf8d9b018a261",
            "placeholder": "​",
            "style": "IPY_MODEL_5d0e25cd97dc4820814d8995533fe513",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "64aaa0d8ae374a45ab14a4c1150a2209": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9677ca77a4df4dd4afbd4e11823d500d",
            "placeholder": "​",
            "style": "IPY_MODEL_a3dab7b5de3142ada052c0524502159b",
            "value": " 2/2 [01:04&lt;00:00, 31.30s/it]"
          }
        },
        "65b049c349b744f9b4135e100a5179e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d997f7d997b463cb08872d29e74c7b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f5999974f91454592055cefa9999017": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_141f930c03804c0199b77bad9f4a4e3b",
            "style": "IPY_MODEL_65b049c349b744f9b4135e100a5179e1",
            "value": true
          }
        },
        "7fec9eb62c234dd28b90c5d95a1a1516": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_9bb25ff24ab049ec9effde278b4dbb7c"
          }
        },
        "81d9ea6500d84953a7dd9d05bdc095ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81e55631302a487ba3375dc3c848c3e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89ad607ed583402d94fba906081b22cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9677ca77a4df4dd4afbd4e11823d500d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a060499ac9540078832cecbd0734cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b17487c219374f97a61ba41b87f27a88",
            "placeholder": "​",
            "style": "IPY_MODEL_5896c2b61a1c4691bd3cde8e88fab612",
            "value": ""
          }
        },
        "9bb25ff24ab049ec9effde278b4dbb7c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "a2fa6a6086664fcab68bd59f725c2be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "a3dab7b5de3142ada052c0524502159b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b17487c219374f97a61ba41b87f27a88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9354b185e124903acd0fe8deee1518f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce52c05a92354e1790580c0a1cc99b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9354b185e124903acd0fe8deee1518f",
            "placeholder": "​",
            "style": "IPY_MODEL_81d9ea6500d84953a7dd9d05bdc095ca",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "ce7e50a60fa5448eb10518228133c7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4d13c4e9cc7444aa011ac045c638db8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9e9dac7c1124fe888d9d535ecfba522": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d997f7d997b463cb08872d29e74c7b3",
            "placeholder": "​",
            "style": "IPY_MODEL_32b3046c42244f63aea88d917176b8e4",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "dadecfc5e56c4f57b07dfd38930a03f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f455c39f2f648c196cdb76154ca3f72",
              "IPY_MODEL_5477ef249f0f4d6c8e86eb6e7a248438",
              "IPY_MODEL_64aaa0d8ae374a45ab14a4c1150a2209"
            ],
            "layout": "IPY_MODEL_d4d13c4e9cc7444aa011ac045c638db8"
          }
        },
        "ea141cbca2ed4389beecf8d9b018a261": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fddee47e4bc7423da72ccc61522bed6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_81e55631302a487ba3375dc3c848c3e6",
            "style": "IPY_MODEL_a2fa6a6086664fcab68bd59f725c2be6",
            "tooltip": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
